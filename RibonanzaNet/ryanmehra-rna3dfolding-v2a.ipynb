{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":87793,"databundleVersionId":11553390,"sourceType":"competition"},{"sourceId":7639698,"sourceType":"datasetVersion","datasetId":4299272},{"sourceId":8318191,"sourceType":"datasetVersion","datasetId":4459124}],"dockerImageVersionId":31011,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Developer** : Ryan Mehra\n\n**Competition** : [Stanford RNA 3D Folding](https://www.kaggle.com/competitions/stanford-rna-3d-folding/)\n\n**Approach**\n\nv1-mvp: Build end-to-end CNN as experimental start\n\nv2-mvp: Compare physics-based protocol FARFAR2 with Kaggle's deepâ€‘learning model (RibonanzaNet2)","metadata":{}},{"cell_type":"markdown","source":"# I. Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport random\nimport pickle\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:47:11.118916Z","iopub.execute_input":"2025-04-24T14:47:11.119120Z","iopub.status.idle":"2025-04-24T14:47:12.682716Z","shell.execute_reply.started":"2025-04-24T14:47:11.119103Z","shell.execute_reply":"2025-04-24T14:47:12.682092Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# II. Config","metadata":{}},{"cell_type":"code","source":"#set seed for everything\ntorch.manual_seed(0)\nnp.random.seed(0)\nrandom.seed(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:47:12.683524Z","iopub.execute_input":"2025-04-24T14:47:12.683895Z","iopub.status.idle":"2025-04-24T14:47:12.691126Z","shell.execute_reply.started":"2025-04-24T14:47:12.683870Z","shell.execute_reply":"2025-04-24T14:47:12.690411Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"config = {\n    \"seed\": 0,\n    \"cutoff_date\": \"2020-01-01\",\n    \"test_cutoff_date\": \"2022-05-01\",\n    \"max_len\": 384,\n    \"batch_size\": 10,\n    \"learning_rate\": 1e-4,\n    \"weight_decay\": 0.0,\n    \"mixed_precision\": \"bf16\",\n    \"model_config_path\": \"../working/configs/pairwise.yaml\",  # Adjust path as needed\n    \"epochs\": 10,\n    \"cos_epoch\": 5,\n    \"loss_power_scale\": 1.0,\n    \"max_cycles\": 1,\n    \"grad_clip\": 0.1,\n    \"gradient_accumulation_steps\": 1,\n    \"d_clamp\": 30,\n    \"max_len_filter\": 9999999,\n    \"min_len_filter\": 10, \n    \"structural_violation_epoch\": 50,\n    \"balance_weight\": False,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:47:12.693588Z","iopub.execute_input":"2025-04-24T14:47:12.693861Z","iopub.status.idle":"2025-04-24T14:47:12.720369Z","shell.execute_reply.started":"2025-04-24T14:47:12.693833Z","shell.execute_reply":"2025-04-24T14:47:12.719734Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# III. Data Prepration","metadata":{}},{"cell_type":"code","source":"# Load data\n\ntrain_sequences=pd.read_csv(\"/kaggle/input/stanford-rna-3d-folding/train_sequences.csv\")\ntrain_labels=pd.read_csv(\"/kaggle/input/stanford-rna-3d-folding/train_labels.csv\")\n\nvalidation_sequences=pd.read_csv(\"/kaggle/input/stanford-rna-3d-folding/validation_sequences.csv\")\nvalidation_labels=pd.read_csv(\"/kaggle/input/stanford-rna-3d-folding/validation_labels.csv\")\n\ntest_sequences=pd.read_csv(\"/kaggle/input/stanford-rna-3d-folding/test_sequences.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:47:12.721085Z","iopub.execute_input":"2025-04-24T14:47:12.721271Z","iopub.status.idle":"2025-04-24T14:47:13.216347Z","shell.execute_reply.started":"2025-04-24T14:47:12.721257Z","shell.execute_reply":"2025-04-24T14:47:13.215603Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_labels[\"pdb_id\"] = train_labels[\"ID\"].apply(lambda x: x.split(\"_\")[0]+'_'+x.split(\"_\")[1])\nvalidation_labels[\"pdb_id\"] = validation_labels[\"ID\"].apply(lambda x: x.split(\"_\")[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:47:13.217156Z","iopub.execute_input":"2025-04-24T14:47:13.217376Z","iopub.status.idle":"2025-04-24T14:47:13.302613Z","shell.execute_reply.started":"2025-04-24T14:47:13.217359Z","shell.execute_reply":"2025-04-24T14:47:13.301756Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_sequences.shape, train_labels.shape, validation_sequences.shape, validation_labels.shape, test_sequences.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:47:13.303604Z","iopub.execute_input":"2025-04-24T14:47:13.303843Z","iopub.status.idle":"2025-04-24T14:47:13.310477Z","shell.execute_reply.started":"2025-04-24T14:47:13.303825Z","shell.execute_reply":"2025-04-24T14:47:13.309725Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"((844, 5), (137095, 7), (12, 5), (2515, 124), (12, 5))"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"train_sequences.head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:47:13.311267Z","iopub.execute_input":"2025-04-24T14:47:13.311456Z","iopub.status.idle":"2025-04-24T14:47:13.337130Z","shell.execute_reply.started":"2025-04-24T14:47:13.311440Z","shell.execute_reply":"2025-04-24T14:47:13.336395Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"  target_id                       sequence temporal_cutoff  \\\n0    1SCL_A  GGGUGCUCAGUACGAGAGGAACCGCACCC      1995-01-26   \n\n                            description  \\\n0  THE SARCIN-RICIN LOOP, A MODULAR RNA   \n\n                                       all_sequences  \n0  >1SCL_1|Chain A|RNA SARCIN-RICIN LOOP|Rattus n...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target_id</th>\n      <th>sequence</th>\n      <th>temporal_cutoff</th>\n      <th>description</th>\n      <th>all_sequences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1SCL_A</td>\n      <td>GGGUGCUCAGUACGAGAGGAACCGCACCC</td>\n      <td>1995-01-26</td>\n      <td>THE SARCIN-RICIN LOOP, A MODULAR RNA</td>\n      <td>&gt;1SCL_1|Chain A|RNA SARCIN-RICIN LOOP|Rattus n...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"train_labels.head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:47:13.337760Z","iopub.execute_input":"2025-04-24T14:47:13.337940Z","iopub.status.idle":"2025-04-24T14:47:13.346388Z","shell.execute_reply.started":"2025-04-24T14:47:13.337925Z","shell.execute_reply":"2025-04-24T14:47:13.345681Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"         ID resname  resid    x_1        y_1    z_1  pdb_id\n0  1SCL_A_1       G      1  13.76 -25.974001  0.102  1SCL_A","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>resname</th>\n      <th>resid</th>\n      <th>x_1</th>\n      <th>y_1</th>\n      <th>z_1</th>\n      <th>pdb_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1SCL_A_1</td>\n      <td>G</td>\n      <td>1</td>\n      <td>13.76</td>\n      <td>-25.974001</td>\n      <td>0.102</td>\n      <td>1SCL_A</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"validation_sequences.head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:47:13.348589Z","iopub.execute_input":"2025-04-24T14:47:13.348838Z","iopub.status.idle":"2025-04-24T14:47:13.366565Z","shell.execute_reply.started":"2025-04-24T14:47:13.348816Z","shell.execute_reply":"2025-04-24T14:47:13.365978Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"  target_id                                           sequence  \\\n0     R1107  GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUU...   \n\n  temporal_cutoff                                        description  \\\n0      2022-05-28  CPEB3 ribozyme\\nHuman\\nhuman CPEB3 HDV-like ri...   \n\n                                       all_sequences  \n0  >7QR4_1|Chain A|U1 small nuclear ribonucleopro...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target_id</th>\n      <th>sequence</th>\n      <th>temporal_cutoff</th>\n      <th>description</th>\n      <th>all_sequences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>R1107</td>\n      <td>GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUU...</td>\n      <td>2022-05-28</td>\n      <td>CPEB3 ribozyme\\nHuman\\nhuman CPEB3 HDV-like ri...</td>\n      <td>&gt;7QR4_1|Chain A|U1 small nuclear ribonucleopro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"## Validation Labels has many coordinates, we do not have this in the training set, for the first run we will ignore the rest and just pick the first XYZ set\nvalidation_labels.head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:47:13.367234Z","iopub.execute_input":"2025-04-24T14:47:13.367474Z","iopub.status.idle":"2025-04-24T14:47:13.392722Z","shell.execute_reply.started":"2025-04-24T14:47:13.367457Z","shell.execute_reply":"2025-04-24T14:47:13.391986Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"        ID resname  resid    x_1   y_1    z_1           x_2           y_2  \\\n0  R1107_1       G      1 -5.499  8.52  8.605 -1.000000e+18 -1.000000e+18   \n\n            z_2           x_3  ...          x_38          y_38          z_38  \\\n0 -1.000000e+18 -1.000000e+18  ... -1.000000e+18 -1.000000e+18 -1.000000e+18   \n\n           x_39          y_39          z_39          x_40          y_40  \\\n0 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18   \n\n           z_40  pdb_id  \n0 -1.000000e+18   R1107  \n\n[1 rows x 124 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>resname</th>\n      <th>resid</th>\n      <th>x_1</th>\n      <th>y_1</th>\n      <th>z_1</th>\n      <th>x_2</th>\n      <th>y_2</th>\n      <th>z_2</th>\n      <th>x_3</th>\n      <th>...</th>\n      <th>x_38</th>\n      <th>y_38</th>\n      <th>z_38</th>\n      <th>x_39</th>\n      <th>y_39</th>\n      <th>z_39</th>\n      <th>x_40</th>\n      <th>y_40</th>\n      <th>z_40</th>\n      <th>pdb_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>R1107_1</td>\n      <td>G</td>\n      <td>1</td>\n      <td>-5.499</td>\n      <td>8.52</td>\n      <td>8.605</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>...</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>R1107</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows Ã— 124 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"test_sequences.head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:47:13.393780Z","iopub.execute_input":"2025-04-24T14:47:13.394076Z","iopub.status.idle":"2025-04-24T14:47:13.408038Z","shell.execute_reply.started":"2025-04-24T14:47:13.394053Z","shell.execute_reply":"2025-04-24T14:47:13.407413Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"  target_id                                           sequence  \\\n0     R1107  GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUU...   \n\n  temporal_cutoff                                        description  \\\n0      2022-05-28  CPEB3 ribozyme\\nHuman\\nhuman CPEB3 HDV-like ri...   \n\n                                       all_sequences  \n0  >7QR4_1|Chain A|U1 small nuclear ribonucleopro...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target_id</th>\n      <th>sequence</th>\n      <th>temporal_cutoff</th>\n      <th>description</th>\n      <th>all_sequences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>R1107</td>\n      <td>GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUU...</td>\n      <td>2022-05-28</td>\n      <td>CPEB3 ribozyme\\nHuman\\nhuman CPEB3 HDV-like ri...</td>\n      <td>&gt;7QR4_1|Chain A|U1 small nuclear ribonucleopro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"_tmp = pd.DataFrame()\n_tmp['temporal_cutoff'] = pd.to_datetime(train_sequences['temporal_cutoff'])\n\nyear_counts = (\n    _tmp\n    .groupby(_tmp['temporal_cutoff'].dt.year)\n    .size()\n    .rename('count')\n)\nprint(year_counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:39:26.124014Z","iopub.execute_input":"2025-04-24T01:39:26.124283Z","iopub.status.idle":"2025-04-24T01:39:26.146203Z","shell.execute_reply.started":"2025-04-24T01:39:26.124254Z","shell.execute_reply":"2025-04-24T01:39:26.145391Z"}},"outputs":[{"name":"stdout","text":"temporal_cutoff\n1995     6\n1996     4\n1997    17\n1998    20\n1999    13\n2000    15\n2001    24\n2002    17\n2003    30\n2004    19\n2005    30\n2006    44\n2007    30\n2008    39\n2009     9\n2010    26\n2011    17\n2012    17\n2013    21\n2014    77\n2015    26\n2016    24\n2017    25\n2018    19\n2019    33\n2020    47\n2021    28\n2022    47\n2023    40\n2024    80\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"## Build all coordinates as list per target_id\n\nall_xyz_coord_trng = []\nall_xyz_coord_val = []\n\nfor pdb_id in tqdm(train_sequences['target_id']):\n    df = train_labels[train_labels[\"pdb_id\"] == pdb_id]\n    xyz = df[['x_1','y_1','z_1']].to_numpy().astype('float32')\n\n    # 1) Build a mask array, initialized to False\n    mask = np.zeros_like(xyz, dtype=bool)\n    finite_mask = np.isfinite(xyz)\n\n    # 2) Only compare where values are finite, write into mask\n    np.less(xyz, -1e17, out=mask, where=finite_mask)\n\n    # 3) Assign NaN to all positions flagged by mask\n    xyz[mask] = np.nan\n\n    all_xyz_coord_trng.append(xyz)\n\n\nfor pdb_id in tqdm(validation_sequences['target_id']):\n    df = validation_labels[validation_labels[\"pdb_id\"] == pdb_id]\n    xyz = df[['x_1','y_1','z_1']].to_numpy().astype('float32')\n\n    # 1) Build a mask array, initialized to False\n    mask = np.zeros_like(xyz, dtype=bool)\n    finite_mask = np.isfinite(xyz)\n\n    # 2) Only compare where values are finite, write into mask\n    np.less(xyz, -1e17, out=mask, where=finite_mask)\n\n    # 3) Assign NaN to all positions flagged by mask\n    xyz[mask] = np.nan\n\n    all_xyz_coord_val.append(xyz)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:39:26.146960Z","iopub.execute_input":"2025-04-24T01:39:26.147156Z","iopub.status.idle":"2025-04-24T01:39:34.393988Z","shell.execute_reply.started":"2025-04-24T01:39:26.147141Z","shell.execute_reply":"2025-04-24T01:39:34.393307Z"}},"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:08<00:00, 102.79it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 1070.77it/s]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"len(all_xyz_coord_trng), len(all_xyz_coord_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:39:34.397037Z","iopub.execute_input":"2025-04-24T01:39:34.397271Z","iopub.status.idle":"2025-04-24T01:39:34.402301Z","shell.execute_reply.started":"2025-04-24T01:39:34.397253Z","shell.execute_reply":"2025-04-24T01:39:34.401702Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(844, 12)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"\"\"\"\nFilter and process data\n\tâ€¢\tfinds and prints the maximum coordinate-sequence length.\n\tâ€¢\tkeeps only those RNAs whose coordinate arrays have\n    \t1.\tâ‰¤ 50% missing values,\n    \t2.\tlength within your configured min(10), max(9999) bounds.\n\tâ€¢\tIt then filters your sequence labels and coordinate data down to that clean subset.\n\"\"\"\n\n#### Process is required for only Training Data, expected to have clean Validaton Data\n\n# initialize stats\nlengths = [len(xyz) for xyz in all_xyz_coord_trng]\nmax_len = max(lengths)\nmin_len = min(lengths)\ntotal = len(all_xyz_coord_trng)\n\n# build filter mask\nfilter_mask = []\nfor xyz in all_xyz_coord_trng:\n    frac_nan = np.isnan(xyz).mean()\n    seq_len = len(xyz)\n    keep = (\n        (frac_nan <= 0.5) and\n        (seq_len < config['max_len_filter']) and\n        (seq_len > config['min_len_filter'])\n    )\n    filter_mask.append(keep)\n\nfilter_mask = np.array(filter_mask)\nkept_indices = np.nonzero(filter_mask)[0]\ndropped = total - len(kept_indices)\n\n# apply filter\ntrain_sequences = train_sequences.loc[kept_indices].reset_index(drop=True)\nall_xyz_coord_trng = [all_xyz_coord_trng[i] for i in kept_indices]\n\n# print stats\nprint(f\"Total sequences initially : {total}\")\nprint(f\" Kept                    : {len(kept_indices)}\")\nprint(f\" Dropped                 : {dropped}\")\nprint(f\"Shortest sequence length : {min_len}\")\nprint(f\"Longest sequence length  : {max_len}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:39:34.403255Z","iopub.execute_input":"2025-04-24T01:39:34.403524Z","iopub.status.idle":"2025-04-24T01:39:34.427180Z","shell.execute_reply.started":"2025-04-24T01:39:34.403501Z","shell.execute_reply":"2025-04-24T01:39:34.426278Z"}},"outputs":[{"name":"stdout","text":"Total sequences initially : 844\n Kept                    : 765\n Dropped                 : 79\nShortest sequence length : 3\nLongest sequence length  : 4298\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"#pack data into a dictionary\n\ntraining_data={\n      \"sequence\":train_sequences['sequence'].to_list(),\n      \"temporal_cutoff\": train_sequences['temporal_cutoff'].to_list(),\n      \"description\": train_sequences['description'].to_list(),\n      \"all_sequences\": train_sequences['all_sequences'].to_list(),\n      \"xyz\": all_xyz_coord_trng\n}\n\nvalidation_data={\n      \"sequence\":validation_sequences['sequence'].to_list(),\n      \"temporal_cutoff\": validation_sequences['temporal_cutoff'].to_list(),\n      \"description\": validation_sequences['description'].to_list(),\n      \"all_sequences\": validation_sequences['all_sequences'].to_list(),\n      \"xyz\": all_xyz_coord_val\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:39:34.427947Z","iopub.execute_input":"2025-04-24T01:39:34.428250Z","iopub.status.idle":"2025-04-24T01:39:34.438013Z","shell.execute_reply.started":"2025-04-24T01:39:34.428223Z","shell.execute_reply":"2025-04-24T01:39:34.437323Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"next(iter(training_data['sequence'])), next(iter(training_data['temporal_cutoff'])), next(iter(training_data['description'])), next(iter(training_data['all_sequences'])), next(iter(training_data['xyz']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:39:34.438710Z","iopub.execute_input":"2025-04-24T01:39:34.438945Z","iopub.status.idle":"2025-04-24T01:39:34.460339Z","shell.execute_reply.started":"2025-04-24T01:39:34.438921Z","shell.execute_reply":"2025-04-24T01:39:34.459671Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"('GGGUGCUCAGUACGAGAGGAACCGCACCC',\n '1995-01-26',\n 'THE SARCIN-RICIN LOOP, A MODULAR RNA',\n '>1SCL_1|Chain A|RNA SARCIN-RICIN LOOP|Rattus norvegicus (10116)\\nGGGUGCUCAGUACGAGAGGAACCGCACCC\\n',\n array([[ 13.76 , -25.974,   0.102],\n        [  9.31 , -29.638,   2.669],\n        [  5.529, -27.813,   5.878],\n        [  2.678, -24.901,   9.793],\n        [  1.827, -20.136,  11.793],\n        [  2.04 , -14.908,  11.771],\n        [  1.107, -11.513,   7.517],\n        [  2.991,  -6.406,   4.783],\n        [  0.896,  -1.193,   7.608],\n        [  0.228,   2.646,   9.128],\n        [  4.329,   2.718,   4.804],\n        [  5.165,   4.792,  -0.914],\n        [  2.61 ,   9.495,  -2.308],\n        [  1.174,  13.829,   0.201],\n        [  1.58 ,  20.115,   3.76 ],\n        [ -1.575,  16.928,   5.897],\n        [ -6.051,  14.762,   5.224],\n        [ -5.554,  10.415,   4.309],\n        [ -3.107,   6.405,   2.12 ],\n        [ -1.41 ,   3.335,  -2.655],\n        [  1.866,  -0.716,  -4.333],\n        [  3.655,  -4.444,  -2.485],\n        [  5.314,  -7.656,   1.13 ],\n        [  7.931,  -9.528,   5.781],\n        [  8.735, -12.648,  10.025],\n        [  9.108, -17.296,  13.021],\n        [  8.897, -22.606,  14.308],\n        [  9.673, -28.338,  13.292],\n        [ 12.641, -30.907,   9.645]], dtype=float32))"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"next(iter(validation_data['sequence'])), next(iter(validation_data['temporal_cutoff'])), next(iter(validation_data['description'])), next(iter(validation_data['all_sequences'])), next(iter(validation_data['xyz']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:39:34.461354Z","iopub.execute_input":"2025-04-24T01:39:34.461641Z","iopub.status.idle":"2025-04-24T01:39:34.478373Z","shell.execute_reply.started":"2025-04-24T01:39:34.461617Z","shell.execute_reply":"2025-04-24T01:39:34.477635Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"('GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUUGCACUCCGGCUGCGAAUUCUGCU',\n '2022-05-28',\n 'CPEB3 ribozyme\\nHuman\\nhuman CPEB3 HDV-like ribozyme',\n '>7QR4_1|Chain A|U1 small nuclear ribonucleoprotein A|Homo sapiens (9606)\\nRPNHTIYINNLNEKIKKDELKKSLHAIFSRFGQILDILVSRSLKMRGQAFVIFKEVSSATNALRSMQGFPFYDKPMRIQYAKTDSDIIAKM\\n>7QR4_2|Chain B|RNA CPEB3 ribozyme|Homo sapiens (9606)\\nGGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUUGCACUCCGGCUGCGAAUUCUGCU',\n array([[ -5.499,   8.52 ,   8.605],\n        [ -5.826,  10.453,  14.01 ],\n        [ -5.849,  14.768,  17.585],\n        [ -5.784,  19.985,  18.666],\n        [ -5.755,  25.533,  17.133],\n        [ -6.227,  30.093,  13.965],\n        [ -9.016,  37.03 ,  11.306],\n        [ -9.026,  31.554,   8.725],\n        [-13.912,  30.908,   8.347],\n        [-22.273,  33.251,   7.105],\n        [-25.752,  28.854,   8.548],\n        [-28.567,  25.027,   6.709],\n        [-30.613,  22.207,   2.6  ],\n        [-30.474,  20.334,  -2.326],\n        [-27.767,  19.594,  -7.189],\n        [-23.651,  18.543,  -9.927],\n        [-18.346,  17.526, -10.079],\n        [-14.495,  14.756,  -6.948],\n        [-12.226,  11.54 ,  -2.988],\n        [-12.133,   6.884,  -0.685],\n        [-13.113,   2.074,  -3.019],\n        [-11.573,  -3.812,  -7.131],\n        [-16.438,  -1.312,  -8.293],\n        [-20.966,   1.049,  -7.393],\n        [-24.439,   2.62 ,  -2.646],\n        [-23.891,   4.653,   2.306],\n        [-20.261,   8.218,   3.57 ],\n        [-16.805,  12.194,   3.278],\n        [-14.387,  16.975,   0.235],\n        [-12.614,  25.407,   1.589],\n        [ -7.741,  27.681,   3.608],\n        [ -3.404,  27.703,   6.278],\n        [ -0.717,  26.032,  11.747],\n        [  0.829,  22.255,  15.457],\n        [  1.217,  17.186,  17.263],\n        [  0.834,  12.36 ,  15.467],\n        [ -0.609,   5.81 ,  13.418],\n        [  0.956,   4.59 ,   9.147],\n        [  4.068,   4.526,   4.559],\n        [  8.814,   6.117,   2.51 ],\n        [ 14.008,   8.127,   2.405],\n        [ 19.014,   8.055,   4.043],\n        [ 21.665,   6.771,   8.892],\n        [ 22.598,   3.317,  12.527],\n        [ 22.091,  -1.661,  14.137],\n        [ 24.278,  -9.164,  13.356],\n        [ 20.785,  -8.101,  17.464],\n        [ 17.436, -14.432,  22.072],\n        [ 12.312, -12.17 ,  22.169],\n        [  6.683, -13.699,  23.004],\n        [  3.918,  -5.926,  25.492],\n        [  4.289,  -0.881,  21.864],\n        [  9.086,   1.973,  21.079],\n        [ 16.475,   3.952,  17.51 ],\n        [ 18.069,   8.888,  15.325],\n        [ 17.173,  12.436,  11.335],\n        [ 14.308,  13.742,   7.049],\n        [  9.791,  13.742,   3.894],\n        [  4.825,  12.507,   1.842],\n        [  0.262,  12.657,   4.783],\n        [ -6.263,  13.102,  -0.265],\n        [-11.415,  15.28 ,  -2.214],\n        [-14.993,  21.784,  -4.451],\n        [-18.298,  24.105,  -7.385],\n        [-22.713,  26.337,  -8.678],\n        [-28.129,  26.549,  -6.813],\n        [-32.032,  27.917,  -2.885],\n        [-33.89 ,  29.199,   2.106],\n        [-33.667,  31.807,   7.123]], dtype=float32))"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"# IV. Training Data Prepration","metadata":{}},{"cell_type":"code","source":"## No need to split from the training set, as we have validaton set \n# all_index = np.arange(len(data['sequence']))\n# cutoff_date = pd.Timestamp(config['cutoff_date'])\n# test_cutoff_date = pd.Timestamp(config['test_cutoff_date'])\n# train_index = [i for i, d in enumerate(data['temporal_cutoff']) if pd.Timestamp(d) <= cutoff_date]\n# test_index = [i for i, d in enumerate(data['temporal_cutoff']) if pd.Timestamp(d) > cutoff_date and pd.Timestamp(d) <= test_cutoff_date]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:39:34.479165Z","iopub.execute_input":"2025-04-24T01:39:34.479409Z","iopub.status.idle":"2025-04-24T01:39:34.493562Z","shell.execute_reply.started":"2025-04-24T01:39:34.479384Z","shell.execute_reply":"2025-04-24T01:39:34.492941Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# print(f\"Train size: {len(train_index)}\")\n# print(f\"Test size: {len(test_index)}\")\n\nprint(f\"Train size: {len(training_data['sequence'])}\")\nprint(f\"Validation size: {len(validation_data['sequence'])}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:39:34.494382Z","iopub.execute_input":"2025-04-24T01:39:34.494585Z","iopub.status.idle":"2025-04-24T01:39:34.509436Z","shell.execute_reply.started":"2025-04-24T01:39:34.494568Z","shell.execute_reply":"2025-04-24T01:39:34.508610Z"}},"outputs":[{"name":"stdout","text":"Train size: 765\nValidation size: 12\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"**Pytorch Dataset**","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom ast import literal_eval\n\ndef get_ct(bp,s):\n    ct_matrix=np.zeros((len(s),len(s)))\n    for b in bp:\n        ct_matrix[b[0]-1,b[1]-1]=1\n    return ct_matrix\n\n\nclass RNA3D_Dataset(torch.utils.data.Dataset):\n    def __init__(self, data: dict, config: dict):\n        \"\"\"\n        data: dict of lists, keys include:\n              'sequence' (list of str), 'xyz' (list of Nx3 arrays), etc.\n        config: dict with at least 'max_len' key\n        \"\"\"\n        self.data   = data\n        self.config = config\n\n        # build token map for known nucleotides\n        self.tokens = {nt: i for i, nt in enumerate('ACGU')}\n        # assign an ID for unknown tokens\n        self.UNK_ID = len(self.tokens)\n\n    def __len__(self):\n        return len(self.data['sequence'])\n    \n    def __getitem__(self, idx):\n        # --- sequence to IDs, unknown â†’ UNK_ID ---\n        seq_str = self.data['sequence'][idx]\n        seq_ids = [ self.tokens.get(nt, self.UNK_ID) for nt in seq_str ]\n        sequence = torch.tensor(seq_ids, dtype=torch.long)\n\n        # --- xyz list â†’ tensor ---\n        xyz_arr = np.array(self.data['xyz'][idx], dtype=np.float32)\n        xyz     = torch.tensor(xyz_arr,   dtype=torch.float32)\n\n        # --- optional random crop if too long ---\n        max_len = self.config['max_len']\n        if len(sequence) > max_len:\n            start = np.random.randint(0, len(sequence) - max_len + 1)\n            end   = start + max_len\n            sequence = sequence[start:end]\n            xyz       = xyz[start:end]\n        \n        return {\n            'sequence': sequence,\n            'xyz':       xyz\n        }\n        \n# class RNA3D_Dataset(Dataset):\n#     # def __init__(self,indices,data):\n#     def __init__(self,data):\n#         # self.indices=indices\n#         self.data=data\n#         self.tokens={nt:i for i,nt in enumerate('ACGU')}\n\n#     def __len__(self):\n#         return len(self.data['sequence'])\n    \n#     def __getitem__(self, idx):\n\n#         # idx=self.indices[idx]\n#         sequence=[self.tokens[nt] for nt in (self.data['sequence'][idx])]\n#         sequence=np.array(sequence)\n#         sequence=torch.tensor(sequence)\n\n#         #get C1' xyz\n#         xyz=self.data['xyz'][idx]\n#         xyz=torch.tensor(np.array(xyz))\n\n\n#         if len(sequence)>config['max_len']:\n#             crop_start=np.random.randint(len(sequence)-config['max_len'])\n#             crop_end=crop_start+config['max_len']\n\n#             sequence=sequence[crop_start:crop_end]\n#             xyz=xyz[crop_start:crop_end]\n        \n\n#         return {'sequence':sequence,\n#                 'xyz':xyz}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:47:18.965174Z","iopub.execute_input":"2025-04-24T14:47:18.965471Z","iopub.status.idle":"2025-04-24T14:47:18.973634Z","shell.execute_reply.started":"2025-04-24T14:47:18.965450Z","shell.execute_reply":"2025-04-24T14:47:18.972819Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# train_dataset=RNA3D_Dataset(train_index,data)\n# val_dataset=RNA3D_Dataset(test_index,data)\n\ntrain_dataset=RNA3D_Dataset(training_data, config)\nval_dataset=RNA3D_Dataset(validation_data, config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:44:19.192110Z","iopub.execute_input":"2025-04-24T01:44:19.192648Z","iopub.status.idle":"2025-04-24T01:44:19.196421Z","shell.execute_reply.started":"2025-04-24T01:44:19.192625Z","shell.execute_reply":"2025-04-24T01:44:19.195598Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"train_dataset.__getitem__(0), val_dataset.__getitem__(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:44:20.770669Z","iopub.execute_input":"2025-04-24T01:44:20.770985Z","iopub.status.idle":"2025-04-24T01:44:20.783357Z","shell.execute_reply.started":"2025-04-24T01:44:20.770965Z","shell.execute_reply":"2025-04-24T01:44:20.782631Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"({'sequence': tensor([2, 2, 2, 3, 2, 1, 3, 1, 0, 2, 3, 0, 1, 2, 0, 2, 0, 2, 2, 0, 0, 1, 1, 2,\n          1, 0, 1, 1, 1]),\n  'xyz': tensor([[ 13.7600, -25.9740,   0.1020],\n          [  9.3100, -29.6380,   2.6690],\n          [  5.5290, -27.8130,   5.8780],\n          [  2.6780, -24.9010,   9.7930],\n          [  1.8270, -20.1360,  11.7930],\n          [  2.0400, -14.9080,  11.7710],\n          [  1.1070, -11.5130,   7.5170],\n          [  2.9910,  -6.4060,   4.7830],\n          [  0.8960,  -1.1930,   7.6080],\n          [  0.2280,   2.6460,   9.1280],\n          [  4.3290,   2.7180,   4.8040],\n          [  5.1650,   4.7920,  -0.9140],\n          [  2.6100,   9.4950,  -2.3080],\n          [  1.1740,  13.8290,   0.2010],\n          [  1.5800,  20.1150,   3.7600],\n          [ -1.5750,  16.9280,   5.8970],\n          [ -6.0510,  14.7620,   5.2240],\n          [ -5.5540,  10.4150,   4.3090],\n          [ -3.1070,   6.4050,   2.1200],\n          [ -1.4100,   3.3350,  -2.6550],\n          [  1.8660,  -0.7160,  -4.3330],\n          [  3.6550,  -4.4440,  -2.4850],\n          [  5.3140,  -7.6560,   1.1300],\n          [  7.9310,  -9.5280,   5.7810],\n          [  8.7350, -12.6480,  10.0250],\n          [  9.1080, -17.2960,  13.0210],\n          [  8.8970, -22.6060,  14.3080],\n          [  9.6730, -28.3380,  13.2920],\n          [ 12.6410, -30.9070,   9.6450]])},\n {'sequence': tensor([2, 2, 2, 2, 2, 1, 1, 0, 1, 0, 2, 1, 0, 2, 0, 0, 2, 1, 2, 3, 3, 1, 0, 1,\n          2, 3, 1, 2, 1, 0, 2, 1, 1, 1, 1, 3, 2, 3, 1, 0, 2, 1, 1, 0, 3, 3, 2, 1,\n          0, 1, 3, 1, 1, 2, 2, 1, 3, 2, 1, 2, 0, 0, 3, 3, 1, 3, 2, 1, 3]),\n  'xyz': tensor([[ -5.4990,   8.5200,   8.6050],\n          [ -5.8260,  10.4530,  14.0100],\n          [ -5.8490,  14.7680,  17.5850],\n          [ -5.7840,  19.9850,  18.6660],\n          [ -5.7550,  25.5330,  17.1330],\n          [ -6.2270,  30.0930,  13.9650],\n          [ -9.0160,  37.0300,  11.3060],\n          [ -9.0260,  31.5540,   8.7250],\n          [-13.9120,  30.9080,   8.3470],\n          [-22.2730,  33.2510,   7.1050],\n          [-25.7520,  28.8540,   8.5480],\n          [-28.5670,  25.0270,   6.7090],\n          [-30.6130,  22.2070,   2.6000],\n          [-30.4740,  20.3340,  -2.3260],\n          [-27.7670,  19.5940,  -7.1890],\n          [-23.6510,  18.5430,  -9.9270],\n          [-18.3460,  17.5260, -10.0790],\n          [-14.4950,  14.7560,  -6.9480],\n          [-12.2260,  11.5400,  -2.9880],\n          [-12.1330,   6.8840,  -0.6850],\n          [-13.1130,   2.0740,  -3.0190],\n          [-11.5730,  -3.8120,  -7.1310],\n          [-16.4380,  -1.3120,  -8.2930],\n          [-20.9660,   1.0490,  -7.3930],\n          [-24.4390,   2.6200,  -2.6460],\n          [-23.8910,   4.6530,   2.3060],\n          [-20.2610,   8.2180,   3.5700],\n          [-16.8050,  12.1940,   3.2780],\n          [-14.3870,  16.9750,   0.2350],\n          [-12.6140,  25.4070,   1.5890],\n          [ -7.7410,  27.6810,   3.6080],\n          [ -3.4040,  27.7030,   6.2780],\n          [ -0.7170,  26.0320,  11.7470],\n          [  0.8290,  22.2550,  15.4570],\n          [  1.2170,  17.1860,  17.2630],\n          [  0.8340,  12.3600,  15.4670],\n          [ -0.6090,   5.8100,  13.4180],\n          [  0.9560,   4.5900,   9.1470],\n          [  4.0680,   4.5260,   4.5590],\n          [  8.8140,   6.1170,   2.5100],\n          [ 14.0080,   8.1270,   2.4050],\n          [ 19.0140,   8.0550,   4.0430],\n          [ 21.6650,   6.7710,   8.8920],\n          [ 22.5980,   3.3170,  12.5270],\n          [ 22.0910,  -1.6610,  14.1370],\n          [ 24.2780,  -9.1640,  13.3560],\n          [ 20.7850,  -8.1010,  17.4640],\n          [ 17.4360, -14.4320,  22.0720],\n          [ 12.3120, -12.1700,  22.1690],\n          [  6.6830, -13.6990,  23.0040],\n          [  3.9180,  -5.9260,  25.4920],\n          [  4.2890,  -0.8810,  21.8640],\n          [  9.0860,   1.9730,  21.0790],\n          [ 16.4750,   3.9520,  17.5100],\n          [ 18.0690,   8.8880,  15.3250],\n          [ 17.1730,  12.4360,  11.3350],\n          [ 14.3080,  13.7420,   7.0490],\n          [  9.7910,  13.7420,   3.8940],\n          [  4.8250,  12.5070,   1.8420],\n          [  0.2620,  12.6570,   4.7830],\n          [ -6.2630,  13.1020,  -0.2650],\n          [-11.4150,  15.2800,  -2.2140],\n          [-14.9930,  21.7840,  -4.4510],\n          [-18.2980,  24.1050,  -7.3850],\n          [-22.7130,  26.3370,  -8.6780],\n          [-28.1290,  26.5490,  -6.8130],\n          [-32.0320,  27.9170,  -2.8850],\n          [-33.8900,  29.1990,   2.1060],\n          [-33.6670,  31.8070,   7.1230]])})"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"import plotly.graph_objects as go\nimport numpy as np\n\n\n\n# Example: Generate an Nx3 matrix\nxyz = train_dataset[200]['xyz']  # Replace this with your actual Nx3 data\nN = len(xyz)\n\n\nfor _ in range(2): #plot twice because it doesnt show up on first try for some reason\n    # Extract columns\n    x, y, z = xyz[:, 0], xyz[:, 1], xyz[:, 2]\n    \n    # Create the 3D scatter plot\n    fig = go.Figure(data=[go.Scatter3d(\n        x=x, y=y, z=z,\n        mode='markers+lines', #'markers',\n        marker=dict(\n            size=5,\n            color=z,  # Coloring based on z-value\n            colorscale='Viridis',  # Choose a colorscale\n            opacity=0.8\n        )\n    )])\n    \n    # Customize layout\n    fig.update_layout(\n        scene=dict(\n            xaxis_title=\"X\",\n            yaxis_title=\"Y\",\n            zaxis_title=\"Z\"\n        ),\n        title=\"3D Scatter Plot\"\n    )\n\nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:44:39.957172Z","iopub.execute_input":"2025-04-24T01:44:39.957460Z","iopub.status.idle":"2025-04-24T01:44:40.126700Z","shell.execute_reply.started":"2025-04-24T01:44:39.957438Z","shell.execute_reply":"2025-04-24T01:44:40.125977Z"}},"outputs":[{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"143c5460-a2be-4ad2-a2b7-487ed6935d55\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"143c5460-a2be-4ad2-a2b7-487ed6935d55\")) {                    Plotly.newPlot(                        \"143c5460-a2be-4ad2-a2b7-487ed6935d55\",                        [{\"marker\":{\"color\":[154.615,148.024,142.896,140.169,137.563,136.952,135.138,128.608,126.919,132.816,133.262,131.336,127.95,122.032,121.28,122.164,116.933,112.248,109.671,116.625,115.869,119.624,118.334,121.155,124.6,128.597,130.363,129.459,125.456,121.122,117.29,115.467,117.498,120.964,124.006,130.263,132.125,129.148,124.713,120.249,115.907,114.247,115.601,118.962,123.159,125.588,127.173,126.294,134.921,134.193,132.344,129.745,126.339,122.021,117.137,110.487,113.69,119.656,123.623,122.945,124.206,128.354,132.269,136.573,140.823,142.604,143.255,144.001,144.778,148.377,null,null,null,null,null,null],\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"opacity\":0.8,\"size\":5},\"mode\":\"markers+lines\",\"x\":[116.203,119.349,117.892,112.561,107.852,103.232,99.938,95.874,88.079,83.445,85.004,87.823,91.247,93.846,98.663,105.846,109.021,106.294,99.613,96.924,95.127,94.918,90.937,86.906,83.313,80.192,78.487,76.708,74.138,70.967,67.654,64.494,61.034,56.659,49.759,52.993,57.96,61.179,63.944,65.609,68.085,71.17,74.333,77.485,80.918,85.341,91.766,97.938,99.753,102.439,107.546,112.04,115.364,116.505,115.225,113.182,109.252,107.751,101.196,105.227,113.048,116.007,115.355,113.223,108.247,102.606,100.182,101.821,106.467,111.927,null,null,null,null,null,null],\"y\":[58.432,54.06,51.643,50.315,50.504,53.765,58.959,58.926,61.994,61.759,56.05,51.351,51.8,51.56,53.542,50.66,58.157,59.985,56.534,60.412,68.236,60.766,55.475,52.311,51.159,52.704,57.163,62.474,65.335,65.921,64.514,60.257,57.013,57.185,59.419,55.799,54.798,52.584,49.746,50.957,54.071,57.961,61.442,64.807,66.662,65.467,63.222,62.459,65.489,69.952,72.418,71.857,68.573,65.524,64.678,67.134,64.817,63.348,60.56,57.02,59.152,61.709,65.162,67.833,68.888,66.279,58.94,52.75,49.583,44.027,null,null,null,null,null,null],\"z\":[154.615,148.024,142.896,140.169,137.563,136.952,135.138,128.608,126.919,132.816,133.262,131.336,127.95,122.032,121.28,122.164,116.933,112.248,109.671,116.625,115.869,119.624,118.334,121.155,124.6,128.597,130.363,129.459,125.456,121.122,117.29,115.467,117.498,120.964,124.006,130.263,132.125,129.148,124.713,120.249,115.907,114.247,115.601,118.962,123.159,125.588,127.173,126.294,134.921,134.193,132.344,129.745,126.339,122.021,117.137,110.487,113.69,119.656,123.623,122.945,124.206,128.354,132.269,136.573,140.823,142.604,143.255,144.001,144.778,148.377,null,null,null,null,null,null],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"xaxis\":{\"title\":{\"text\":\"X\"}},\"yaxis\":{\"title\":{\"text\":\"Y\"}},\"zaxis\":{\"title\":{\"text\":\"Z\"}}},\"title\":{\"text\":\"3D Scatter Plot\"}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('143c5460-a2be-4ad2-a2b7-487ed6935d55');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"### Do this later post defining batch sizes \n\n# ## Create dataloader instances \n\n# train_loader=DataLoader(train_dataset,batch_size=1,shuffle=True)\n# val_loader=DataLoader(val_dataset,batch_size=1,shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:44:43.160607Z","iopub.execute_input":"2025-04-24T01:44:43.161303Z","iopub.status.idle":"2025-04-24T01:44:43.164640Z","shell.execute_reply.started":"2025-04-24T01:44:43.161281Z","shell.execute_reply":"2025-04-24T01:44:43.163822Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"#! pip install einops","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:44:44.737100Z","iopub.execute_input":"2025-04-24T01:44:44.737857Z","iopub.status.idle":"2025-04-24T01:44:44.740996Z","shell.execute_reply.started":"2025-04-24T01:44:44.737831Z","shell.execute_reply":"2025-04-24T01:44:44.740294Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"# V. Create Custom Model Instance\n\nWe will add a linear layer to predict xyz of C1' atoms on the base /kaggle/input/ribonanzanet2d-final \n\n","metadata":{}},{"cell_type":"code","source":"import sys\n\nsys.path.append(\"/kaggle/input/ribonanzanet2d-final\")\n\nfrom Network import *\nimport yaml\n\n\n\nclass Config:\n    def __init__(self, **entries):\n        self.__dict__.update(entries)\n        self.entries=entries\n\n    def print(self):\n        print(self.entries)\n\ndef load_config_from_yaml(file_path):\n    with open(file_path, 'r') as file:\n        config = yaml.safe_load(file)\n    return Config(**config)\n\n\n\nclass finetuned_RibonanzaNet(RibonanzaNet):\n    def __init__(self, config, pretrained=False):\n        config.dropout=0.1\n        super(finetuned_RibonanzaNet, self).__init__(config)\n        if pretrained:\n            self.load_state_dict(torch.load(\"/kaggle/input/ribonanzanet-weights/RibonanzaNet.pt\",map_location='cpu'))\n        # self.ct_predictor=nn.Sequential(nn.Linear(64,256),\n        #                                 nn.ReLU(),\n        #                                 nn.Linear(256,64),\n        #                                 nn.ReLU(),\n        #                                 nn.Linear(64,1)) \n        self.dropout=nn.Dropout(0.0)\n        self.xyz_predictor=nn.Linear(256,3)\n\n\n    \n    def forward(self,src):\n        \n        #with torch.no_grad():\n        sequence_features, pairwise_features=self.get_embeddings(src, torch.ones_like(src).long().to(src.device))\n\n\n        xyz=self.xyz_predictor(sequence_features)\n\n        return xyz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:47:33.558523Z","iopub.execute_input":"2025-04-24T14:47:33.558817Z","iopub.status.idle":"2025-04-24T14:47:35.957491Z","shell.execute_reply.started":"2025-04-24T14:47:33.558795Z","shell.execute_reply":"2025-04-24T14:47:35.956984Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"## Available GPUs \nprint(\"GPUs available:\", torch.cuda.device_count())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:44:52.106776Z","iopub.execute_input":"2025-04-24T01:44:52.107444Z","iopub.status.idle":"2025-04-24T01:44:52.130997Z","shell.execute_reply.started":"2025-04-24T01:44:52.107420Z","shell.execute_reply":"2025-04-24T01:44:52.130358Z"}},"outputs":[{"name":"stdout","text":"GPUs available: 1\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"from pprint import pprint\ncfg = load_config_from_yaml(\"/kaggle/input/ribonanzanet2d-final/configs/pairwise.yaml\")\n\n## Update the batch size to new value\n_batch_size= 5\n\ncfg.batch_size = _batch_size\ncfg.entries['batch_size'] = _batch_size\n\n## Update the GPUs to multiple if multiple available \nif torch.cuda.device_count() > 1:\n    cfg.gpu_id = \"0,1\"\n    cfg.entries['gpu_id'] = \"0,1\"\n    \npprint(vars(cfg))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:48:32.653412Z","iopub.execute_input":"2025-04-24T14:48:32.653908Z","iopub.status.idle":"2025-04-24T14:48:32.691212Z","shell.execute_reply.started":"2025-04-24T14:48:32.653890Z","shell.execute_reply":"2025-04-24T14:48:32.690571Z"}},"outputs":[{"name":"stdout","text":"{'batch_size': 5,\n 'bpp_file_folder': '../../input/bpp_files/',\n 'dropout': 0.05,\n 'entries': {'batch_size': 5,\n             'bpp_file_folder': '../../input/bpp_files/',\n             'dropout': 0.05,\n             'epochs': 40,\n             'fold': 0,\n             'gpu_id': '0',\n             'gradient_accumulation_steps': 2,\n             'input_dir': '../../input/',\n             'k': 9,\n             'learning_rate': 0.001,\n             'nclass': 2,\n             'nfolds': 6,\n             'nhead': 8,\n             'ninp': 256,\n             'nlayers': 9,\n             'ntoken': 5,\n             'optimizer': 'ranger',\n             'pairwise_dimension': 64,\n             'test_batch_size': 8,\n             'use_bpp': False,\n             'use_grad_checkpoint': True,\n             'use_triangular_attention': False,\n             'weight_decay': 0.0001},\n 'epochs': 40,\n 'fold': 0,\n 'gpu_id': '0',\n 'gradient_accumulation_steps': 2,\n 'input_dir': '../../input/',\n 'k': 9,\n 'learning_rate': 0.001,\n 'nclass': 2,\n 'nfolds': 6,\n 'nhead': 8,\n 'ninp': 256,\n 'nlayers': 9,\n 'ntoken': 5,\n 'optimizer': 'ranger',\n 'pairwise_dimension': 64,\n 'test_batch_size': 8,\n 'use_bpp': False,\n 'use_grad_checkpoint': True,\n 'use_triangular_attention': False,\n 'weight_decay': 0.0001}\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"## Create dataloader instances \n\n# train_loader=DataLoader(train_dataset,batch_size=1,shuffle=True)\n# val_loader=DataLoader(val_dataset,batch_size=1,shuffle=False)\n\nimport torch\nfrom torch.nn.utils.rnn import pad_sequence\n\ndef pad_collate(batch):\n    # batch is a list of dicts, e.g. {'sequence': Tensor[L], 'xyz': Tensor[L,3], â€¦}\n    seqs = [torch.tensor(item['sequence']) for item in batch]\n    xyzs = [torch.tensor(item['xyz'], dtype=torch.float32) for item in batch]\n\n    # pad to the max length in this batch\n    seqs_padded = pad_sequence(seqs, batch_first=True, padding_value=0)       # or pad_token\n    xyzs_padded = pad_sequence(xyzs, batch_first=True, padding_value=float('nan'))\n\n    # collect any other fields you need, e.g. labels\n    # labels = torch.stack([item['label'] for item in batch], 0)\n\n    return {\n        'sequence': seqs_padded,\n        'xyz':       xyzs_padded,\n        # 'label':    labels,\n    }\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:50:21.366857Z","iopub.execute_input":"2025-04-24T14:50:21.367427Z","iopub.status.idle":"2025-04-24T14:50:21.372643Z","shell.execute_reply.started":"2025-04-24T14:50:21.367392Z","shell.execute_reply":"2025-04-24T14:50:21.372012Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# then in your DataLoader:\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=cfg.batch_size,\n    shuffle=True,\n    num_workers=0,\n    pin_memory=True,\n    collate_fn=pad_collate\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=cfg.batch_size,\n    shuffle=False,\n    num_workers=0,\n    pin_memory=True,\n    collate_fn=pad_collate\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model=finetuned_RibonanzaNet(load_config_from_yaml(\"/kaggle/input/ribonanzanet2d-final/configs/pairwise.yaml\"),pretrained=True).cuda()\n\n# instantiate on CPU first\nmodel = finetuned_RibonanzaNet(cfg, pretrained=True)\n\n# wrap in DataParallel (uses all available GPUs by default)\nmodel = torch.nn.DataParallel(model)\n\n# then move to CUDA\nmodel = model.cuda()\n\n# after wrapping in DataParallel\n# print(\"Model sees config:\", model.module.cfg.batch_size, model.module.cfg.gpu_id)\n\nprint(\"GPUs visible:\", torch.cuda.device_count())\n\nprint(\"DataParallel device IDs:\", model.device_ids)\nprint(\"First parameter on device:\", next(model.parameters()).device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:44:58.113407Z","iopub.execute_input":"2025-04-24T01:44:58.113666Z","iopub.status.idle":"2025-04-24T01:44:58.476881Z","shell.execute_reply.started":"2025-04-24T01:44:58.113649Z","shell.execute_reply":"2025-04-24T01:44:58.476276Z"}},"outputs":[{"name":"stdout","text":"constructing 9 ConvTransformerEncoderLayers\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_202/377864876.py:30: FutureWarning:\n\nYou are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n\n","output_type":"stream"},{"name":"stdout","text":"GPUs visible: 1\nDataParallel device IDs: [0]\nFirst parameter on device: cuda:0\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"**Define Loss Function**\n\nwe will use dRMSD loss on the predicted xyz. the loss function is invariant to translations, rotations, and reflections. because dRMSD is invariant to reflections, it cannot distinguish chiral structures, so there may be better loss functions","metadata":{}},{"cell_type":"code","source":"def calculate_distance_matrix(X,Y,epsilon=1e-4):\n    return (torch.square(X[:,None]-Y[None,:])+epsilon).sum(-1).sqrt()\n\n\ndef dRMSD(pred_x,\n          pred_y,\n          gt_x,\n          gt_y,\n          epsilon=1e-4,Z=10,d_clamp=None):\n    pred_dm=calculate_distance_matrix(pred_x,pred_y)\n    gt_dm=calculate_distance_matrix(gt_x,gt_y)\n\n\n\n    mask=~torch.isnan(gt_dm)\n    mask[torch.eye(mask.shape[0]).bool()]=False\n\n    if d_clamp is not None:\n        rmsd=(torch.square(pred_dm[mask]-gt_dm[mask])+epsilon).clip(0,d_clamp**2)\n    else:\n        rmsd=torch.square(pred_dm[mask]-gt_dm[mask])+epsilon\n\n    return rmsd.sqrt().mean()/Z\n\ndef local_dRMSD(pred_x,\n          pred_y,\n          gt_x,\n          gt_y,\n          epsilon=1e-4,Z=10,d_clamp=30):\n    pred_dm=calculate_distance_matrix(pred_x,pred_y)\n    gt_dm=calculate_distance_matrix(gt_x,gt_y)\n\n\n\n    mask=(~torch.isnan(gt_dm))*(gt_dm<d_clamp)\n    mask[torch.eye(mask.shape[0]).bool()]=False\n\n\n\n    rmsd=torch.square(pred_dm[mask]-gt_dm[mask])+epsilon\n    # rmsd=(torch.square(pred_dm[mask]-gt_dm[mask])+epsilon).sqrt()/Z\n    #rmsd=torch.abs(pred_dm[mask]-gt_dm[mask])/Z\n    return rmsd.sqrt().mean()/Z\n\ndef dRMAE(pred_x,\n          pred_y,\n          gt_x,\n          gt_y,\n          epsilon=1e-4,Z=10,d_clamp=None):\n    pred_dm=calculate_distance_matrix(pred_x,pred_y)\n    gt_dm=calculate_distance_matrix(gt_x,gt_y)\n\n\n\n    mask=~torch.isnan(gt_dm)\n    mask[torch.eye(mask.shape[0]).bool()]=False\n\n    rmsd=torch.abs(pred_dm[mask]-gt_dm[mask])\n\n    return rmsd.mean()/Z\n\nimport torch\n\ndef align_svd_mae(input, target, Z=10):\n    \"\"\"\n    Align input (Nx3) to target (Nx3) via Procrustes (SVD) in float32,\n    then compute MAE / Z.\n    \"\"\"\n    assert input.shape == target.shape, \"Input and target must match\"\n\n    # 1) Mask out NaNs\n    mask = ~torch.isnan(target.sum(-1))\n    inp = input[mask].float()   # cast to float32\n    tgt = target[mask].float()  # cast to float32\n\n    # 2) Compute and remove centroids\n    c_inp = inp.mean(dim=0, keepdim=True)\n    c_tgt = tgt.mean(dim=0, keepdim=True)\n    inp_c = inp - c_inp\n    tgt_c = tgt - c_tgt\n\n    # 3) Covariance matrix\n    cov = inp_c.t() @ tgt_c\n\n    # 4) SVD in float32\n    #    Detach so no gradients flow through the SVD\n    with torch.no_grad():\n        U, S, Vt = torch.svd(cov)\n        R = Vt @ U.t()\n        # fix potential reflection\n        if torch.det(R) < 0:\n            Vt[-1, :] *= -1\n            R = Vt @ U.t()\n\n    # 5) Rotate back and re-add centroid\n    #    (R is already float32, inp_c is float32)\n    aligned = inp_c @ R.t() + c_tgt\n\n    # 6) MAE loss (float32)\n    loss = torch.abs(aligned - tgt).mean() / Z\n\n    return loss\n    \n# def align_svd_mae(input, target, Z=10):\n#     \"\"\"\n#     Aligns the input (Nx3) to target (Nx3) using SVD-based Procrustes alignment\n#     and computes RMSD loss.\n    \n#     Args:\n#         input (torch.Tensor): Nx3 tensor representing the input points.\n#         target (torch.Tensor): Nx3 tensor representing the target points.\n    \n#     Returns:\n#         aligned_input (torch.Tensor): Nx3 aligned input.\n#         rmsd_loss (torch.Tensor): RMSD loss.\n#     \"\"\"\n#     assert input.shape == target.shape, \"Input and target must have the same shape\"\n\n#     #mask \n#     mask=~torch.isnan(target.sum(-1))\n\n#     input=input[mask]\n#     target=target[mask]\n    \n#     # Compute centroids\n#     centroid_input = input.mean(dim=0, keepdim=True)\n#     centroid_target = target.mean(dim=0, keepdim=True)\n\n#     # Center the points\n#     input_centered = input - centroid_input.detach()\n#     target_centered = target - centroid_target\n\n#     # Compute covariance matrix\n#     cov_matrix = input_centered.T @ target_centered\n\n#     # SVD to find optimal rotation\n#     U, S, Vt = torch.svd(cov_matrix)\n\n#     # Compute rotation matrix\n#     R = Vt @ U.T\n\n#     # Ensure a proper rotation (det(R) = 1, no reflection)\n#     if torch.det(R) < 0:\n#         Vt[-1, :] *= -1\n#         R = Vt @ U.T\n\n#     # Rotate input\n#     aligned_input = (input_centered @ R.T.detach()) + centroid_target.detach()\n\n#     # # Compute RMSD loss\n#     # rmsd_loss = torch.sqrt(((aligned_input - target) ** 2).mean())\n\n#     # rmsd_loss = torch.sqrt(((aligned_input - target) ** 2).mean())\n    \n#     # return aligned_input, rmsd_loss\n#     return torch.abs(aligned_input-target).mean()/Z","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:45:01.861490Z","iopub.execute_input":"2025-04-24T01:45:01.861774Z","iopub.status.idle":"2025-04-24T01:45:01.874200Z","shell.execute_reply.started":"2025-04-24T01:45:01.861753Z","shell.execute_reply":"2025-04-24T01:45:01.873373Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"**Training Loop**","metadata":{}},{"cell_type":"code","source":"# from tqdm import tqdm\n# from torch.amp import GradScaler\n# # from torch.cuda.amp import autocast, GradScaler\n\n# epochs=50\n# cos_epoch=35\n\n\n# best_loss=np.inf\n# optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.0, lr=0.0001) #no weight decay following AF\n\n# batch_size=_batch_size\n\n# #for cycle in range(2):\n\n# criterion=torch.nn.BCEWithLogitsLoss(reduction='none')\n\n# scaler = GradScaler()\n\n# schedule=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(epochs-cos_epoch)*len(train_loader)//batch_size)\n\n# best_val_loss=99999999999\n# for epoch in range(epochs):\n#     model.train()\n#     tbar=tqdm(train_loader)\n#     total_loss=0\n#     oom=0\n#     for idx, batch in enumerate(tbar):\n#         #try:\n\n#         sequence=batch['sequence'].cuda()\n#         gt_xyz=batch['xyz'].cuda().squeeze()\n\n#         #with torch.autocast(device_type='cuda', dtype=torch.float16):\n#         pred_xyz=model(sequence).squeeze()\n        \n#         loss=dRMAE(pred_xyz,pred_xyz,gt_xyz,gt_xyz) + align_svd_mae(pred_xyz, gt_xyz)\n#              #local_dRMSD(pred_xyz,pred_xyz,gt_xyz,gt_xyz)\n\n#         if loss!=loss:\n#             stop\n\n        \n#         (loss/batch_size).backward()\n\n#         if (idx+1)%batch_size==0 or idx+1 == len(tbar):\n\n#             torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n#             optimizer.step()\n#             optimizer.zero_grad()\n#             # scaler.scale(loss/batch_size).backward()\n#             # scaler.unscale_(optimizer)\n#             # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n#             # scaler.step(optimizer)\n#             # scaler.update()\n\n            \n#             if (epoch+1)>cos_epoch:\n#                 schedule.step()\n#         #schedule.step()\n#         total_loss+=loss.item()\n        \n#         tbar.update(1)\n#         tbar.set_description(f\"Epoch {epoch + 1} Loss: {total_loss/(idx+1)} OOMs: {oom}\")\n\n\n\n#         # except Exception:\n#         #     #print(Exception)\n#         #     oom+=1\n#     tbar=tqdm(val_loader)\n#     model.eval()\n#     val_preds=[]\n#     val_loss=0\n#     for idx, batch in enumerate(tbar):\n#         sequence=batch['sequence'].cuda()\n#         gt_xyz=batch['xyz'].cuda().squeeze()\n\n#         with torch.no_grad():\n#             pred_xyz=model(sequence).squeeze()\n#             loss=dRMAE(pred_xyz,pred_xyz,gt_xyz,gt_xyz)\n            \n#         val_loss+=loss.item()\n#         val_preds.append([gt_xyz.cpu().numpy(),pred_xyz.cpu().numpy()])\n#     val_loss=val_loss/len(tbar)\n#     print(f\"val loss: {val_loss}\")\n    \n    \n    \n#     if val_loss<best_val_loss:\n#         best_val_loss=val_loss\n#         best_preds=val_preds\n#         torch.save(model.state_dict(),'RibonanzaNet-3D_RM.pt')\n\n#     # 1.053595052265986 train loss after epoch 0\n# torch.save(model.state_dict(),'RibonanzaNet-3D-final_RM.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:45:06.058121Z","iopub.execute_input":"2025-04-24T01:45:06.058732Z","iopub.status.idle":"2025-04-24T01:45:06.063367Z","shell.execute_reply.started":"2025-04-24T01:45:06.058711Z","shell.execute_reply":"2025-04-24T01:45:06.062528Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"from torch.cuda.amp import autocast, GradScaler\nfrom tqdm import tqdm\n\noptimizer = torch.optim.Adam(\n    model.parameters(),\n    lr=cfg.learning_rate,\n    weight_decay=cfg.weight_decay\n)\n\n\nepochs    = 50\ncos_epoch = 35\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n    optimizer,\n    T_max=(epochs - cos_epoch) * len(train_loader) // cfg.batch_size\n)\nscaler = GradScaler()\n\n# ---- TRAIN & VALIDATION LOOP ----\nbest_val_loss = float('inf')\n\nfor epoch in range(1, epochs + 1):\n    # TRAINING\n    model.train()\n    optimizer.zero_grad(set_to_none=True)\n    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\", unit=\"batch\")\n    running_loss = 0.0\n\n    for idx, batch in enumerate(train_bar, start=1):\n        seq = batch['sequence'].cuda(non_blocking=True)\n        gt  = batch['xyz'].cuda(non_blocking=True).squeeze()\n\n        # 1) compute dRMAE in fp16\n        with autocast():\n            pred = model(seq).squeeze()\n            dR_loss = dRMAE(pred, pred, gt, gt) #+ align_svd_mae(pred, gt)\n\n        # 2) compute alignment loss in fp32\n        with autocast(enabled=False):\n            rot_loss = align_svd_mae(pred, gt)  # SVD runs in fp32\n\n        loss = dR_loss + rot_loss\n\n        scaler.scale(loss).backward()\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad(set_to_none=True)\n\n        running_loss += loss.item()\n        if idx % 10 == 0:\n            train_bar.set_postfix(loss=running_loss / idx)\n\n    # LR SCHEDULER STEP\n    if epoch > cos_epoch:\n        scheduler.step()\n\n    # VALIDATION\n    model.eval()\n    val_loss = 0.0\n    val_bar = tqdm(val_loader, desc=\"Validation\", unit=\"batch\")\n    with torch.no_grad():\n        for batch in val_bar:\n            seq = batch['sequence'].cuda(non_blocking=True)\n            gt  = batch['xyz'].cuda(non_blocking=True).squeeze()\n            pred = model(seq).squeeze()\n            vloss = dRMAE(pred, pred, gt, gt)\n            val_loss += vloss.item()\n\n    val_loss /= len(val_loader)\n    print(f\"Epoch {epoch} Validation Loss: {val_loss:.4f}\")\n\n    # SAVE BEST MODEL\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), 'RibonanzaNet-best-rm.pt')\n        print(f\"  âœ¨ Saved new best model (val_loss={val_loss:.4f})\")\n\n# FINAL SAVE\ntorch.save(model.state_dict(), 'RibonanzaNet-final-rm.pt')\nprint(\"Training complete. Final model saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:45:08.347476Z","iopub.execute_input":"2025-04-24T01:45:08.347885Z","iopub.status.idle":"2025-04-24T08:32:15.714435Z","shell.execute_reply.started":"2025-04-24T01:45:08.347855Z","shell.execute_reply":"2025-04-24T08:32:15.713678Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_202/2929129281.py:17: FutureWarning:\n\n`torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n\nEpoch 1/50:   0%|          | 0/153 [00:00<?, ?batch/s]/tmp/ipykernel_202/1145524360.py:11: UserWarning:\n\nTo copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n\n/tmp/ipykernel_202/1145524360.py:12: UserWarning:\n\nTo copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n\n/tmp/ipykernel_202/2929129281.py:34: FutureWarning:\n\n`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning:\n\ntorch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n\n/tmp/ipykernel_202/2929129281.py:39: FutureWarning:\n\n`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n\nEpoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [07:51<00:00,  3.08s/batch, loss=24.9]\nValidation:   0%|          | 0/3 [00:00<?, ?batch/s]/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning:\n\nNone of the inputs have requires_grad=True. Gradients will be None\n\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.23s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Validation Loss: 14.0704\n  âœ¨ Saved new best model (val_loss=14.0704)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [07:53<00:00,  3.10s/batch, loss=21.6]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Validation Loss: 14.1055\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:18<00:00,  3.26s/batch, loss=21.2]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Validation Loss: 14.1357\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:06<00:00,  3.18s/batch, loss=21.1]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 Validation Loss: 14.1465\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:09<00:00,  3.20s/batch, loss=19.6]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Validation Loss: 14.1737\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:00<00:00,  3.14s/batch, loss=20.2]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 Validation Loss: 13.9068\n  âœ¨ Saved new best model (val_loss=13.9068)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:18<00:00,  3.26s/batch, loss=21.4]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 Validation Loss: 14.2414\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [07:43<00:00,  3.03s/batch, loss=20.2]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 Validation Loss: 13.9289\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:00<00:00,  3.14s/batch, loss=20]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 Validation Loss: 14.1557\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:28<00:00,  3.32s/batch, loss=20.7]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 Validation Loss: 14.1236\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [07:47<00:00,  3.06s/batch, loss=19.5]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 Validation Loss: 14.1344\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:20<00:00,  3.27s/batch, loss=19.5]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 Validation Loss: 14.0620\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:21<00:00,  3.28s/batch, loss=19.9]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 Validation Loss: 13.9490\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [07:49<00:00,  3.07s/batch, loss=19.2]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 Validation Loss: 14.0978\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:11<00:00,  3.21s/batch, loss=19.6]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 Validation Loss: 13.8969\n  âœ¨ Saved new best model (val_loss=13.8969)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [07:57<00:00,  3.12s/batch, loss=19.6]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16 Validation Loss: 14.1233\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:07<00:00,  3.19s/batch, loss=18.9]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17 Validation Loss: 14.1271\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:14<00:00,  3.23s/batch, loss=19.8]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18 Validation Loss: 14.1336\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [07:55<00:00,  3.10s/batch, loss=20]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19 Validation Loss: 13.9990\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:14<00:00,  3.23s/batch, loss=19.5]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20 Validation Loss: 13.9723\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:03<00:00,  3.16s/batch, loss=20.5]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21 Validation Loss: 13.8945\n  âœ¨ Saved new best model (val_loss=13.8945)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:01<00:00,  3.15s/batch, loss=19.7]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22 Validation Loss: 14.1691\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:00<00:00,  3.14s/batch, loss=19.2]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23 Validation Loss: 13.8842\n  âœ¨ Saved new best model (val_loss=13.8842)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:21<00:00,  3.28s/batch, loss=18.9]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24 Validation Loss: 14.1495\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:00<00:00,  3.14s/batch, loss=18.9]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25 Validation Loss: 14.1758\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [07:51<00:00,  3.08s/batch, loss=18.9]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26 Validation Loss: 10.2989\n  âœ¨ Saved new best model (val_loss=10.2989)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:40<00:00,  3.40s/batch, loss=19.1]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27 Validation Loss: 8.9348\n  âœ¨ Saved new best model (val_loss=8.9348)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:06<00:00,  3.18s/batch, loss=19.8]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28 Validation Loss: 9.8874\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:01<00:00,  3.14s/batch, loss=18.5]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29 Validation Loss: 9.1549\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:24<00:00,  3.30s/batch, loss=18.6]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30 Validation Loss: 9.2669\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:10<00:00,  3.20s/batch, loss=18.6]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31 Validation Loss: 8.4199\n  âœ¨ Saved new best model (val_loss=8.4199)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [07:25<00:00,  2.91s/batch, loss=19.3]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32 Validation Loss: 7.7713\n  âœ¨ Saved new best model (val_loss=7.7713)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [07:57<00:00,  3.12s/batch, loss=17.9]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33 Validation Loss: 8.9476\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:06<00:00,  3.18s/batch, loss=17.7]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34 Validation Loss: 7.9089\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [07:47<00:00,  3.05s/batch, loss=17.8]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35 Validation Loss: 10.9635\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:03<00:00,  3.16s/batch, loss=17.9]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36 Validation Loss: 9.1817\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:26<00:00,  3.31s/batch, loss=18.3]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37 Validation Loss: 7.9338\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:14<00:00,  3.23s/batch, loss=18.1]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38 Validation Loss: 8.1174\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:09<00:00,  3.20s/batch, loss=18]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39 Validation Loss: 8.6104\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [07:40<00:00,  3.01s/batch, loss=18.2]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40 Validation Loss: 9.0082\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [07:34<00:00,  2.97s/batch, loss=18.7]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 41 Validation Loss: 8.7924\n","output_type":"stream"},{"name":"stderr","text":"Epoch 42/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:01<00:00,  3.15s/batch, loss=18.4]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42 Validation Loss: 8.7342\n","output_type":"stream"},{"name":"stderr","text":"Epoch 43/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:22<00:00,  3.29s/batch, loss=17]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43 Validation Loss: 9.3102\n","output_type":"stream"},{"name":"stderr","text":"Epoch 44/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:14<00:00,  3.24s/batch, loss=18.4]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 44 Validation Loss: 8.4229\n","output_type":"stream"},{"name":"stderr","text":"Epoch 45/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:38<00:00,  3.39s/batch, loss=18.4]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 45 Validation Loss: 8.9334\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [07:51<00:00,  3.08s/batch, loss=18.2]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 46 Validation Loss: 9.7374\n","output_type":"stream"},{"name":"stderr","text":"Epoch 47/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [08:22<00:00,  3.28s/batch, loss=17.8]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 47 Validation Loss: 9.0753\n","output_type":"stream"},{"name":"stderr","text":"Epoch 48/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [07:55<00:00,  3.11s/batch, loss=18.2]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 48 Validation Loss: 8.2836\n","output_type":"stream"},{"name":"stderr","text":"Epoch 49/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [07:57<00:00,  3.12s/batch, loss=18.3]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 49 Validation Loss: 9.0319\n","output_type":"stream"},{"name":"stderr","text":"Epoch 50/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [07:58<00:00,  3.13s/batch, loss=16.8]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/batch]","output_type":"stream"},{"name":"stdout","text":"Epoch 50 Validation Loss: 9.2478\nTraining complete. Final model saved.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# import torch, gc\n\n# # 1) Delete any large objects you no longer need\n# del model\n# del optimizer\n# del train_loader, val_loader\n# # (also delete any large tensors youâ€™re still holding onto)\n\n# # 2) Force Python to collect garbage\n# gc.collect()\n\n# # 3) Ask CUDA to release its cached memory\n# torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T01:39:34.582173Z","iopub.status.idle":"2025-04-24T01:39:34.582443Z","shell.execute_reply.started":"2025-04-24T01:39:34.582315Z","shell.execute_reply":"2025-04-24T01:39:34.582331Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# VI. Submission","metadata":{}},{"cell_type":"code","source":"## Load model\n\nimport torch\nfrom torch.utils.data import DataLoader\nimport numpy as np\nfrom tqdm import tqdm\n\n# 1) Reconstruct model & load best checkpoint\nmodel = finetuned_RibonanzaNet(cfg, pretrained=False)\nmodel = torch.nn.DataParallel(model).cuda()\nstate = torch.load('/kaggle/working/RibonanzaNet-best-rm.pt', map_location='cuda:0')\nmodel.load_state_dict(state)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:48:44.562553Z","iopub.execute_input":"2025-04-24T14:48:44.563117Z","iopub.status.idle":"2025-04-24T14:48:45.061848Z","shell.execute_reply.started":"2025-04-24T14:48:44.563097Z","shell.execute_reply":"2025-04-24T14:48:45.061114Z"}},"outputs":[{"name":"stdout","text":"constructing 9 ConvTransformerEncoderLayers\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/4165483759.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load('/kaggle/working/RibonanzaNet-best-rm.pt', map_location='cuda:0')\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\n# --- assume `test_sequence` is your DataFrame,\n#     `config`, `cfg`, `model`, `pad_collate`, & `RNA3D_Dataset` are already in scope\n\n# 1) Build a dict of lists for the Dataset, with dummy xyz\ntest_data = {\n    'sequence':      test_sequences['sequence'].tolist(),\n    'xyz':           [np.zeros((config['max_len'], 3), dtype=np.float32)]\n                       * len(test_sequences),   # dummy\n}\n# (we ignore temporal_cutoff / description / all_sequences here)\n\n# 2) Instantiate the Dataset + Loader\ntest_ds = RNA3D_Dataset(test_data, config)\ntest_loader = DataLoader(\n    test_ds,\n    batch_size=cfg.batch_size,\n    shuffle=False,\n    num_workers=0,\n    pin_memory=True,\n    collate_fn=pad_collate\n)\n\n# 3) Inference\nmodel.eval()\nall_preds = []  # will be a list of [L_padded, 3] arrays\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"Predicting\"):\n        seq   = batch['sequence'].cuda(non_blocking=True)\n        preds = model(seq).cpu().numpy()   # shape (B, L_batch, 3)\n        # append each RNA in the batch separately\n        for p in preds:\n            all_preds.append(p)\n\n# now all_preds[i] is the padded-prediction for test i\n# length may vary per-batch, but you'll slice to true L below\n\n# 4) Build submission rows\nrows = []\nfor i, row in test_sequences.iterrows():\n    tid     = row['target_id']\n    seq_str = row['sequence']\n    L       = len(seq_str)\n    coords  = all_preds[i][:L]   # slice off the padding â†’ shape [L,3]\n\n    for j, (x,y,z) in enumerate(coords, start=1):\n        base = {\n            'ID':      f\"{tid}_{j}\",\n            'resname': seq_str[j-1],\n            'resid':   j\n        }\n        # replicate each coordinate 5Ã—\n        for k in range(1, 6):\n            base[f'x_{k}'] = x\n            base[f'y_{k}'] = y\n            base[f'z_{k}'] = z\n        rows.append(base)\n\nsubmission_df = pd.DataFrame(rows)\nprint(\"Final submission shape:\", submission_df.shape)\nsubmission_df.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:53:10.350511Z","iopub.execute_input":"2025-04-24T14:53:10.351127Z","iopub.status.idle":"2025-04-24T14:53:13.715292Z","shell.execute_reply.started":"2025-04-24T14:53:10.351106Z","shell.execute_reply":"2025-04-24T14:53:13.714476Z"}},"outputs":[{"name":"stderr","text":"Predicting:   0%|          | 0/3 [00:00<?, ?it/s]/tmp/ipykernel_31/3691936996.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  seqs = [torch.tensor(item['sequence']) for item in batch]\n/tmp/ipykernel_31/3691936996.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  xyzs = [torch.tensor(item['xyz'], dtype=torch.float32) for item in batch]\nPredicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Final submission shape: (2179, 18)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}